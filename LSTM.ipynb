{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbvgzygk+/vvyn8JdB7dO3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lillaszulyovszky/data-science-retreat-lectures/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-okop1BRoL8i"
      },
      "source": [
        "from tensorflow.keras import models, layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beUf_fXqpwaL"
      },
      "source": [
        "dataset, info = tfds.load(\n",
        "    \n",
        "    \"imdb_reviews/plain_text\",\n",
        "    split=[\"train[:80%]\", \"train[80%:]\", \"test\"],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")\n",
        "\n",
        "dataset_train_original = dataset[0]\n",
        "dataset_validate_original = dataset[1]\n",
        "dataset_test_original = dataset[2]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tk7TPF7pa6s"
      },
      "source": [
        "vocabulary_size = 10000\n",
        "encoder = layers.TextVectorization(\n",
        "    max_tokens= vocabulary_size,\n",
        "    standardize=\"lower_and_strip_punctuation\",\n",
        "    split=\"whitespace\",\n",
        "    output_mode=\"int\",\n",
        ")\n",
        "\n",
        "encoder.adapt(\n",
        "    dataset_train_original.map(lambda text, label: text).batch(1024)\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT6BUomdpozO"
      },
      "source": [
        "dataset_train = dataset_train_original.cache()\n",
        "dataset_train = dataset_train.shuffle(20000)\n",
        "dataset_train = dataset_train.batch(128)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zLNMICJqwSD"
      },
      "source": [
        " dataset_validate = dataset_validate_original.cache().batch(128)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuGtYufLqZ3r",
        "outputId": "673c6f27-5283-4916-813d-9731c28622fe"
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(encoder)\n",
        "model.add(layers.Embedding(input_dim=vocabulary_size, output_dim=32))\n",
        "model.add(layers.LSTM(64, return_sequences=True))\n",
        "model.add(layers.LSTM(96))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    \n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    \n",
        "    dataset_train,\n",
        "    epochs=5,\n",
        "    validation_data=dataset_validate\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization (TextVect (None, None)              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 64)          24832     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 96)                61824     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 97        \n",
            "=================================================================\n",
            "Total params: 406,753\n",
            "Trainable params: 406,753\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "157/157 [==============================] - 565s 4s/step - loss: 0.6934 - accuracy: 0.4997 - val_loss: 0.6933 - val_accuracy: 0.4938\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 555s 4s/step - loss: 0.6933 - accuracy: 0.4962 - val_loss: 0.6932 - val_accuracy: 0.4938\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 558s 4s/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5062\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 564s 4s/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.4952\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 564s 4s/step - loss: 0.6931 - accuracy: 0.4978 - val_loss: 0.6932 - val_accuracy: 0.5056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0efA6hZatnYd"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLnFijXLtn-m"
      },
      "source": [
        "Params calculated: each one is calculated differently.\n",
        "\n",
        "Embeddings: vocab size * output_dim\n",
        "\n",
        "LSTM: addition of layers + multiplication of something?\n",
        "\n",
        "Dense: dense layer number + it's parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "afAlPGAqq2hu",
        "outputId": "8409e2cc-77a4-42e8-beb1-14308c95b5bb"
      },
      "source": [
        "plt.plot(history.history['loss'],label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['accuracy'],label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-20926042efd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLrSdg89s4jI"
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(encoder)\n",
        "model.add(layers.Embedding(input_dim=vocabulary_size, output_dim=32))\n",
        "model.add(layers.GRU(64))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQDSuAgtw8op"
      },
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(encoder)\n",
        "model.add(layers.Embedding(input_dim=vocabulary_size, output_dim=32))\n",
        "model.add(layers.Bidirectional(layers.LSTM(64)))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}