{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Formats - Exercise 1\n",
    "\n",
    "Prove that reading a single column from a parquet file is faster than reading all the columns from the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Test Logging Output\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "# Create logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create STDERR handler\n",
    "handler = logging.StreamHandler(sys.stderr)\n",
    "\n",
    "# Create formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Set STDERR handler as the only handler \n",
    "logger.handlers = [handler]\n",
    "\n",
    "logger.info(\"Test Logging Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Wrote a parquet file containing 40000 records at /tmp/outfile.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MULTIPLIER = 10_000\n",
    "records = [\n",
    "    {u'station': u'011990-99999', u'temp': 0, u'time': 1433269388},\n",
    "    {u'station': u'011990-99999', u'temp': 22, u'time': 1433270389},\n",
    "    {u'station': u'011990-99999', u'temp': -11, u'time': 1433273379},\n",
    "    {u'station': u'012650-99999', u'temp': 111, u'time': 1433275478},\n",
    "] * MULTIPLIER\n",
    "\n",
    "pd_df = pd.DataFrame(records)\n",
    "\n",
    "from fastparquet import write\n",
    "file_path = '/tmp/outfile.parquet'\n",
    "write(file_path, pd_df)\n",
    "\n",
    "logger.info(f\"Wrote a parquet file containing {len(pd_df.index)} records at {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Reading all columns took 6.8668129444122314 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading only 1 column took 1.1175260543823242 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from fastparquet import ParquetFile\n",
    "pf = ParquetFile(file_path)\n",
    "\n",
    "NUM_ITER = 1_000\n",
    "\n",
    "start = time.time()\n",
    "for i in range(NUM_ITER):\n",
    "    pd_df = pf.to_pandas()\n",
    "end = time.time()\n",
    "\n",
    "logger.info(f\"Reading all columns took {end-start} seconds\")\n",
    "\n",
    "start = time.time()\n",
    "for i in range(NUM_ITER):\n",
    "    pd_df = pf.to_pandas(['temp'])\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Reading only 1 column took {end-start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsr-db] *",
   "language": "python",
   "name": "conda-env-dsr-db-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
