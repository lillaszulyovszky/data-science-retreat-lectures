{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pip: command not found\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq requests bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "## What is web scraping?\n",
    "\n",
    "**Web scraping is two sequential steps**\n",
    "1. fetching a webpage HTML\n",
    "2. extracting data from the HTML\n",
    "\n",
    "## Am I allowed to scrape?\n",
    "\n",
    "*I'm not a lawyer, and don't play one on the internet*\n",
    "\n",
    "Web scraping involves extracting data from HTML\n",
    "- this HTML (& data) is publically available through an HTTP request\n",
    "- you only get back what they send you\n",
    "\n",
    "`robots.txt` \n",
    "- way for websites to tell crawlers & webscrapers what is allowed or not\n",
    "- for example - https://www.theguardian.com/robots.txt\n",
    "\n",
    "You should be polite\n",
    "- tell the website who you are (`user-agent`)\n",
    "- don't spam requests - consider adding a `time.sleep` in between requests\n",
    "- spamming the server is not polite\n",
    "- if they offer an API, use that instead\n",
    "\n",
    "If you ever use data from web scraping commercially\n",
    "\n",
    "- check for copyright\n",
    "- i.e. couldn't scrape videos from YouTube & repost \n",
    "\n",
    "## Fetching HTML\n",
    "\n",
    "Web scraping is two steps\n",
    "1. fetching a webpage HTML\n",
    "2. extracting data from the HTML\n",
    "\n",
    "We will be scraping the Wikipedia page for [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun) - one of the three recipients of the 2018 Turing award for work in Deep Learning - the other two being [Geoffery Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton) and [Yoshua Bengio](https://en.wikipedia.org/wiki/Yoshua_Bengio).\n",
    "\n",
    "Let's do an HTTP request to the Wikipedia URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://en.wikipedia.org/wiki/Yann_LeCun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the HTML content we get back using `.text`.\n",
    "\n",
    "This is the same HTML that your browser uses to render a page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>Yann LeCun - Wikipedia</title>\\n<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":!1,\"wgSeparatorTransformTable\":[\"\",\"\"],'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the web?\n",
    "\n",
    "We think of the web as a collection of pages\n",
    "\n",
    "- in fact, the web is a collection of users (usually web browsers, can also be servers) and servers\n",
    "\n",
    "A better mental for the web is a conversation between users & servers\n",
    "\n",
    "## What is a server?\n",
    "\n",
    "It's just a computer running a program\n",
    "\n",
    "- i.e. Flask, which is a Python program\n",
    "\n",
    "Servers can also run & be accessed locally\n",
    "\n",
    "- this is how we use Jupyter Lab :)\n",
    "\n",
    "## HTTP - what happens when you visit a website?\n",
    "\n",
    "This is the kind of conversation that happens when you access a page on the internet:\n",
    "\n",
    "*CLIENT* - request to https://www.reddit.com\n",
    "\n",
    "*SERVER* - I'm the server hosting reddit.com - what page would you like?\n",
    "\n",
    "*CLIENT* - Please give me https://www.reddit.com/r/MachineLearning/\n",
    "\n",
    "*SERVER* - Sure -> sends text files\n",
    "\n",
    "*CLIENT* - Thanks! -> renders text files in browser\n",
    "\n",
    "This kind of conversation is had every time you access a webpage\n",
    "\n",
    "- **it's also the same thing that happens when we do `requests.get`!\n",
    "\n",
    "*Further reading*\n",
    "[Interactive Data Visualization for the Web - Scott Murray](oreilly.com/library/view/interactive-data-visualization/9781449340223/) - in particular Chapter 3\n",
    "\n",
    "## What text files are common on the internet?\n",
    "\n",
    "What do you expect to get back when you send a request\n",
    "1. HTML (`.html`)\n",
    "2. CSS (`.css`)\n",
    "3. Javascript (`.js`)\n",
    "\n",
    "### HTML\n",
    "\n",
    "HTML is a markup language used to format text.  \n",
    "\n",
    "The fundamental primitive is an element.  Elements can have different tags, such as:\n",
    "- `<p>` paragraph\n",
    "- `<h1>` heading\n",
    "- `<a>` link\n",
    "- `<img>` image\n",
    "- `<script>` Javascript\n",
    "\n",
    "These elements can be nested to create complex structure (particularly parent - child, or inheritance relationships).\n",
    "\n",
    "Take a look at `example.html` to see a full HTML document.  You can also use HTML within notebooks (like this one).\n",
    "\n",
    "HTML elements have optional attributes\n",
    "- property `<a property=\"value\">`\n",
    "- class `<a class=\"myClass\">`\n",
    "- id `<a id=\"myID>`\n",
    "\n",
    "Properties are usually stuff like color, and change how the HTML renders\n",
    "- classes & ID's are used to identify\n",
    "\n",
    "### CSS\n",
    "\n",
    "Used to style HTML\n",
    "- you don't need to know this for web scraping\n",
    "\n",
    "### Javascript\n",
    "\n",
    "Dynamic, weakly untyped language\n",
    "\n",
    "- executes in the browser\n",
    "- do fancy stuff like calling API's, dynamically rendering HTML, responding to user input\n",
    "\n",
    "While you don't need to know Javascript for web scraping, it is useful to look out for JSON strings\n",
    "- these can hold useful infomation\n",
    "- example - always check for a `<script type=\"application/ld+json\">`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML 101\n",
    "\n",
    "\n",
    "Tags can have **attributes** - for example the `<a>` usually has an attribute of `href` that holds the link:\n",
    "\n",
    "`<a href=\"https://adgefficiency.com/\">My personal blog</a>`\n",
    "\n",
    "This is rendered as:\n",
    "\n",
    "<a href=\"https://adgefficiency.com/\">My personal blog</a>\n",
    "\n",
    "A common attribute for HTML elements to have is a **class** - this is used to specify the styling of the object to a CSS class.\n",
    "\n",
    "## Parsing HTML\n",
    "\n",
    "We need some way to parse this HTML text - to do this we will use **Beautiful Soup**:\n",
    "\n",
    "We can use Beautiful Soup to parse the HTML for specific tags.  First we create an instance of the `BeautifulSoup` class, taking the HTML text we got using `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://en.wikipedia.org/wiki/Yann_LeCun')\n",
    "soup = BeautifulSoup(response.text)\n",
    "\n",
    "# ul is an \"unordered list\" \n",
    "len(soup.findAll('ul'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **title** tag is a special tag required in all HTML documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Yann LeCun - Wikipedia</title>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Beautiful Soup to find all the `p` tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>In March 2019, LeCun won the Turing award, sharing it with <a href=\"/wiki/Yoshua_Bengio\" title=\"Yoshua Bengio\">Yoshua Bengio</a> and <a href=\"/wiki/Geoffrey_Hinton\" title=\"Geoffrey Hinton\">Geoffrey Hinton</a>.<sup class=\"reference\" id=\"cite_ref-36\"><a href=\"#cite_note-36\">[36]</a></sup> In September 2019, he received the Golden Plate Award of the <a href=\"/wiki/Academy_of_Achievement\" title=\"Academy of Achievement\">American Academy of Achievement</a>.<sup class=\"reference\" id=\"cite_ref-37\"><a href=\"#cite_note-37\">[37]</a></sup>\n",
       "</p>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = soup.find_all('p')\n",
    "\n",
    "p[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to find all the links (`a`) in a page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.mediawiki.org/\"><img alt=\"Powered by MediaWiki\" height=\"31\" loading=\"lazy\" src=\"/static/images/footer/poweredby_mediawiki_88x31.png\" srcset=\"/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/></a>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = soup.find_all('a')\n",
    "p[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer tools\n",
    "\n",
    "One useful tool in web development are the **Developer Tools** included in modern browsers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Inspect elements** tool allows us to find the HTML block for the biography table:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = soup.find('table', attrs={'class': 'infobox biography vcard'})\n",
    "\n",
    "type(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables in HTML\n",
    "\n",
    "`tr` = row\n",
    "\n",
    "`th` = header cell\n",
    "\n",
    "`td` = data cell\n",
    "\n",
    "Let's take a look at the third row (**Born**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr><th class=\"infobox-label\" scope=\"row\">Born</th><td class=\"infobox-data\"><span style=\"display:none\"> (<span class=\"bday\">1960-07-08</span>) </span>July 8, 1960<span class=\"noprint ForceAgeToShow\"> (age 61)</span><br/><div class=\"birthplace\" style=\"display:inline\"><a href=\"/wiki/Soisy-sous-Montmorency\" title=\"Soisy-sous-Montmorency\">Soisy-sous-Montmorency</a>, <a href=\"/wiki/France\" title=\"France\">France</a></div></td></tr>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = [r for r in table.find_all('tr')]\n",
    "row = rows[2]\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<th class=\"infobox-label\" scope=\"row\">Born</th>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.find('th')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"infobox-data\"><span style=\"display:none\"> (<span class=\"bday\">1960-07-08</span>) </span>July 8, 1960<span class=\"noprint ForceAgeToShow\"> (age 61)</span><br/><div class=\"birthplace\" style=\"display:inline\"><a href=\"/wiki/Soisy-sous-Montmorency\" title=\"Soisy-sous-Montmorency\">Soisy-sous-Montmorency</a>, <a href=\"/wiki/France\" title=\"France\">France</a></div></td>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.find('td')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the text from these HTML elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' (1960-07-08) July 8, 1960 (age\\xa061)Soisy-sous-Montmorency, France'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.find('td').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store this data in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "if data:\n",
    "    print('ih')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Born': ' (1960-07-08) July 8, 1960 (age\\xa061)Soisy-sous-Montmorency, France'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "data[row.find('th').text] = row.find('td').text\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - clean the biography table\n",
    "\n",
    "Let's iterate over the rows in the biography table and store each row in a list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from answers import store_biography_table\n",
    "#store_biography_table(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding links\n",
    "\n",
    "Another common task when parsing HTML is to look for links - in HTML links have an `a` tag.  \n",
    "\n",
    "Let's find all the links in the **References** section - which is a `div` element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('div', 'mw-references-wrap mw-references-columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"external text\" href=\"https://www.legifrance.gouv.fr/jo_pdf.do?id=JORFTEXT000039726325\" rel=\"nofollow\">\"Version électronique authentifiée publiée au JO n° 0001 du 01/01/2020 | Legifrance\"</a>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = []\n",
    "for link in table.find_all('a'):\n",
    "    links.append(link)\n",
    "\n",
    "links = [link for link in table.find_all('a')]\n",
    "li = links[1]\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.legifrance.gouv.fr/jo_pdf.do?id=JORFTEXT000039726325'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Version électronique authentifiée publiée au JO n° 0001 du 01/01/2020 | Legifrance\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading images\n",
    "\n",
    "Now we are familiar with Beautiful Soup, we know we can find all the images in a page eaisly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"Yann LeCun - 2018 (cropped).jpg\" data-file-height=\"1490\" data-file-width=\"1297\" decoding=\"async\" height=\"253\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/22/Yann_LeCun_-_2018_%28cropped%29.jpg/220px-Yann_LeCun_-_2018_%28cropped%29.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/2/22/Yann_LeCun_-_2018_%28cropped%29.jpg/330px-Yann_LeCun_-_2018_%28cropped%29.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/22/Yann_LeCun_-_2018_%28cropped%29.jpg/440px-Yann_LeCun_-_2018_%28cropped%29.jpg 2x\" width=\"220\"/>,\n",
       " <img alt=\"\" class=\"thumbimage\" data-file-height=\"2448\" data-file-width=\"3264\" decoding=\"async\" height=\"225\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/84/Yann_LeCun_at_the_University_of_Minnesota.jpg/300px-Yann_LeCun_at_the_University_of_Minnesota.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/84/Yann_LeCun_at_the_University_of_Minnesota.jpg/450px-Yann_LeCun_at_the_University_of_Minnesota.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/84/Yann_LeCun_at_the_University_of_Minnesota.jpg/600px-Yann_LeCun_at_the_University_of_Minnesota.jpg 2x\" width=\"300\"/>,\n",
       " <img alt=\"DNC training recall task.gif\" data-file-height=\"459\" data-file-width=\"919\" decoding=\"async\" height=\"100\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b5/DNC_training_recall_task.gif/200px-DNC_training_recall_task.gif\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/b/b5/DNC_training_recall_task.gif/300px-DNC_training_recall_task.gif 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/b5/DNC_training_recall_task.gif/400px-DNC_training_recall_task.gif 2x\" width=\"200\"/>,\n",
       " <img alt=\"Portal\" class=\"noviewer\" data-file-height=\"185\" data-file-width=\"180\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/16px-Symbol_portal_class.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/23px-Symbol_portal_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/e/e2/Symbol_portal_class.svg/31px-Symbol_portal_class.svg.png 2x\" width=\"16\"/>,\n",
       " <img alt=\"Category\" class=\"noviewer\" data-file-height=\"185\" data-file-width=\"180\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/23px-Symbol_category_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/31px-Symbol_category_class.svg.png 2x\" title=\"Category\" width=\"16\"/>,\n",
       " <img alt=\"Edit this at Wikidata\" data-file-height=\"20\" data-file-width=\"20\" decoding=\"async\" height=\"10\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/15px-OOjs_UI_icon_edit-ltr-progressive.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/20px-OOjs_UI_icon_edit-ltr-progressive.svg.png 2x\" style=\"vertical-align: text-top\" width=\"10\"/>,\n",
       " <img alt=\"\" height=\"1\" src=\"//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" style=\"border: none; position: absolute;\" title=\"\" width=\"1\"/>,\n",
       " <img alt=\"Wikimedia Foundation\" height=\"31\" loading=\"lazy\" src=\"/static/images/footer/wikimedia-button.png\" srcset=\"/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x\" width=\"88\"/>,\n",
       " <img alt=\"Powered by MediaWiki\" height=\"31\" loading=\"lazy\" src=\"/static/images/footer/poweredby_mediawiki_88x31.png\" srcset=\"/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the first one - note that we use the `src` attribute, and have to append `'https:'` onto the url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Yann_LeCun_-_2018_%28cropped%29.jpg/220px-Yann_LeCun_-_2018_%28cropped%29.jpg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = soup.find_all('img')[0]\n",
    "url = 'https:' + img['src']\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `requests` again to get the bytes for this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xff\\xd8\\xff\\xe1\\x00\\x92Exif\\x00\\x00MM\\x00*\\x00\\x00\\x00\\x08\\x00\\x06\\x01\\x1a\\x00\\x05\\x00\\x00\\x00\\x01\\x00\\x00\\x00V\\x01\\x1b\\x00\\x05\\x00\\x00\\x00\\x01\\x00\\x00\\x00^\\x01(\\x00\\x03'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Web Scraping Poems\n",
    "\n",
    "Scrape the poems from the poet Edgar Allen Poe from this website: https://poestories.com/poetry.php\n",
    "\n",
    "Put them in the `./text_files` directory, and run a report on the poems afterwards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
