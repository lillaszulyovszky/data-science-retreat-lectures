{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sPrjeJhFQBmu"
   },
   "source": [
    "# Integrated gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [Axiomatic attribution for deep networks](https://arxiv.org/abs/1703.01365)\n",
    "- [Going deeper with convolutions](https://arxiv.org/abs/1409.4842)\n",
    "- [Attribution baselines](https://distill.pub/2020/attribution-baselines/)\n",
    "- [Riemann sum](https://en.wikipedia.org/wiki/Riemann_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NG17_Wp6ikKf"
   },
   "source": [
    "We will walk through IG step-by-step to understand the pixel feature importances of an image classifier. Let's have a look at this image.\n",
    "\n",
    "<img src = \"../../assets/fireboat.png\" width=\"500\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see:\n",
    "\n",
    "- What is important for classifying this image as an image with a fireboat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GVVV4BGrABkA"
   },
   "source": [
    "### Download a pretrained image classifier from TF-Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v1 = tf.keras.Sequential([\n",
    "    hub.KerasLayer(name='inception_v1', \n",
    "    handle='https://tfhub.dev/google/imagenet/inception_v1/classification/4', \n",
    "    trainable=False)\n",
    "])\n",
    "inception_v1.build([None, 224, 224, 3])\n",
    "inception_v1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inputs**: The input shape for the model is `(None, 224, 224, 3)` \n",
    "\n",
    "**Outputs**: \n",
    " - A `tf.Tensor` of logits in the shape of `(batch_size, 1001)`. \n",
    " - Each row is for one of the 1,001 classes from ImageNet. \n",
    " - Top predicted -`tf.argmax(predictions, axis=-1)`.\n",
    " - Prediction probabilities - `tf.nn.softmax(predictions, axis=-1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading the labels of ImageNet dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "huZnb_O0L9mw"
   },
   "outputs": [],
   "source": [
    "def load_imagenet_labels(file_path):\n",
    "    labels_file = tf.keras.utils.get_file('ImageNetLabels.txt', file_path)\n",
    "    with open(labels_file) as reader:\n",
    "        f = reader.read()\n",
    "        labels = f.splitlines()\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rtrl-u7T6NEk"
   },
   "outputs": [],
   "source": [
    "imagenet_labels = load_imagenet_labels('https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STpIJr1Z5r_u"
   },
   "source": [
    "### Load and preprocess images\n",
    "\n",
    "Let's illustrate IG using two images from [Wikimedia Commons](https://commons.wikimedia.org/wiki/Main_Page): a [Fireboat](https://commons.wikimedia.org/wiki/File:San_Francisco_fireboat_showing_off.jpg), a [Giant Panda](https://commons.wikimedia.org/wiki/File:Giant_Panda_2.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOb0Adq-rU5J"
   },
   "outputs": [],
   "source": [
    "def read_image(file_name):\n",
    "    image = tf.io.read_file(file_name)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize_with_pad(image, target_height=224, target_width=224)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_khLTN75CLMJ"
   },
   "outputs": [],
   "source": [
    "img_url = {\n",
    "    'Fireboat': 'http://storage.googleapis.com/download.tensorflow.org/example_images/San_Francisco_fireboat_showing_off.jpg',\n",
    "    'Giant Panda': 'http://storage.googleapis.com/download.tensorflow.org/example_images/Giant_Panda_2.jpeg',\n",
    "}\n",
    "\n",
    "img_paths = {name: tf.keras.utils.get_file(name, url) for (name, url) in img_url.items()}\n",
    "img_name_tensors = {name: read_image(img_path) for (name, img_path) in img_paths.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two downloaded images are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for n, (name, img_tensors) in enumerate(img_name_tensors.items()):\n",
    "    ax = plt.subplot(1, 2, n+1)\n",
    "    ax.imshow(img_tensors)\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QvTYc8IZKbeO"
   },
   "source": [
    "### Classify images\n",
    "We can classifying these images and display the top 3 most confident predictions. The function top_k_predicted shows the top labels and probabilities of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gsO7ILHZ0By"
   },
   "outputs": [],
   "source": [
    "def top_k_predictions(img, k=3):\n",
    "    # Add batch dim for the model to be able to predict\n",
    "    image_batch = tf.expand_dims(img, axis=0)\n",
    "    predictions = inception_v1(image_batch)\n",
    "    probs = tf.nn.softmax(predictions, axis=-1)\n",
    "    top_probs, top_idxs = tf.math.top_k(input=probs, k=k)\n",
    "    top_labels = imagenet_labels[tuple(top_idxs)]\n",
    "    return top_labels, top_probs[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, img_tensor) in img_name_tensors.items():\n",
    "    plt.imshow(img_tensor)\n",
    "    plt.title(name, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    pred_label, pred_prob = top_k_predictions(img_tensor)\n",
    "    for label, prob in zip(pred_label, pred_prob):\n",
    "        print(f'{label}: {prob:0.1%}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-lH1N4timM2"
   },
   "source": [
    "## Intuition behind Integrated Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our model, Inception V1, is a function mapping the input feature space, values of image pixels, to the output space defined by ImageNet class probabilitiy values in $[0, 1]$ range.\n",
    "- Earlier methods described feature importance using gradients w.r.t. pixels multiplied by pixels values, similar to coefficients of features in Linear Regression. A gradient is telling us which pixels have the steepest local slope with respect to the output\n",
    "- The gradients of input features may have small magnitudes even if the network depends heavily on those features. This can happen if the network function flattens after those features reach a certain magnitude. The gradients *saturate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AUkIUvpkaO8"
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "  \"\"\"A simplified model function.\"\"\"\n",
    "  return tf.where(x < 0.8, x, 0.8)\n",
    "\n",
    "def interpolated_path(x):\n",
    "  \"\"\"A straight line path.\"\"\"\n",
    "  return tf.zeros_like(x)\n",
    "\n",
    "x = tf.linspace(start=0.0, stop=1.0, num=6)\n",
    "y = f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot gradients and IG intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax0 = fig.add_subplot(121)\n",
    "ax0.plot(x, f(x), marker='o')\n",
    "ax0.set_title('Gradient saturates over F(x)', fontweight='bold')\n",
    "ax0.text(0.2, 0.5, 'Gradient > 0 = \\n x is important')\n",
    "ax0.text(0.7, 0.85, 'Gradient = 0 \\n x not important')\n",
    "ax0.set_yticks(tf.range(0, 1.5, 0.5))\n",
    "ax0.set_xticks(tf.range(0, 1.5, 0.5))\n",
    "ax0.set_ylabel('F(x) - model true class predicted probability')\n",
    "ax0.set_xlabel('x - (pixel value)')\n",
    "\n",
    "ax1 = fig.add_subplot(122)\n",
    "ax1.plot(x, f(x), marker='o')\n",
    "ax1.plot(x, interpolated_path(x), marker='>')\n",
    "ax1.set_title('IG intuition', fontweight='bold')\n",
    "ax1.text(0.25, 0.1, 'Accumulate gradients along path')\n",
    "ax1.set_ylabel('F(x) - model true class predicted probability')\n",
    "ax1.set_xlabel('x - (pixel value)')\n",
    "ax1.set_yticks(tf.range(0, 1.5, 0.5))\n",
    "ax1.set_xticks(tf.range(0, 1.5, 0.5))\n",
    "ax1.annotate('Baseline', xy=(0.0, 0.0), xytext=(0.0, 0.2),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1))\n",
    "ax1.annotate('Input', xy=(1.0, 0.0), xytext=(0.95, 0.2),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.1))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LswhGFd0xZBr"
   },
   "source": [
    "* **left**: \n",
    "- The model's gradients for pixel `x` are positive between 0.0 and 0.8 but go to 0.0 between 0.8 and 1.0. \n",
    "- Pixel `x` has a significant impact on pushing the model toward 80% predicted probability on the true class. \n",
    "- *It doesn't make sense that pixel `x`'s importance is small*.\n",
    "\n",
    "* **right**:\n",
    "- Which pixels, when scaled along this path, most increased the network output for the correct class?\n",
    "- IG accumulate pixel `x`'s local gradients and attribute their importance as a score for how much they add or subtract to the model's overall output class probability. Let's break down and compute IG in 3 parts: \n",
    "\n",
    "    1. Interpolate small steps along a straight line in the feature space between 0 (a baseline or starting point) and 1 (input pixel's value).\n",
    "    2. Compute gradients at each step for the model's predictions with respect to each step.\n",
    "    3. Approximate the integral between the baseline and the input by accumulating (cumulative average) these local gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28MU35BCLM-s"
   },
   "source": [
    "### Establish a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A baseline is an input image used as a starting point for calculating feature importance.\n",
    "- Shows the impact of the absence of each pixel on the prediction to contrast with its impact of each pixel on the prediction when present in the input image.\n",
    "- **The choice of the baseline plays a central role in interpreting and visualizing pixel feature importances.**\n",
    "- Let's use a black image here whose pixel values are all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxvpwGkj4G4J"
   },
   "outputs": [],
   "source": [
    "baseline = tf.zeros(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(baseline)\n",
    "plt.title(\"Baseline\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xphryu2mGAk8"
   },
   "source": [
    "### Convert formulas into code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QstMR0IcbfFA"
   },
   "source": [
    "The formula for Integrated Gradients is as follows:\n",
    "\n",
    "$IntegratedGrads_{i}(x) ::= (x_{i} - x'_{i})\\int_{\\alpha=0}^1\\frac{\\partial F(x'+\\alpha \\cdot\n",
    "(x - x'))}{\\partial x_i}{d\\alpha}$\n",
    "\n",
    "where:\n",
    "\n",
    "$_{i}$ = feature   \n",
    "$x$ = input  \n",
    "$x'$ = baseline that represents the \"absence\" of a feature   \n",
    "$\\alpha$ = interpolation constant for feature perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7w8SD5YMqvi"
   },
   "source": [
    "In practice, computing a definite integral is not always numerically possible and can be computationally costly, so you compute the following numerical approximation:\n",
    "\n",
    "$IntegratedGrads^{approx}_{i}(x)::=(x_{i}-x'_{i})\\sum_{k=1}^{m}\\frac{\\partial F(x' + \\frac{k}{m}\\cdot(x - x'))}{\\partial x_{i}} \\cdot \\frac{1}{m}$\n",
    "\n",
    "where:\n",
    "\n",
    "$_{i}$ = feature (individual pixel)  \n",
    "$x$ = input (image tensor)  \n",
    "$x'$ = baseline (image tensor)  \n",
    "$k$ = scaled feature perturbation constant  \n",
    "$m$ = number of steps in the Riemann sum approximation of the integral  \n",
    "$(x_{i}-x'_{i})$ = a term for the difference from the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5aPG68RssS2h"
   },
   "source": [
    "### Interpolate images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pPrldEYsIR4M"
   },
   "source": [
    "$IntegratedGrads^{approx}_{i}(x)::=(x_{i}-x'_{i})\\sum_{k=1}^{m}\\frac{\\partial F(\\overbrace{x' + \\frac{k}{m}\\cdot(x - x')}^\\text{interpolate m images at k intervals})}{\\partial x_{i}} \\cdot\\frac{1}{m}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4r-ZrIIsdbI"
   },
   "source": [
    "- Let's generate a [linear interpolation](https://en.wikipedia.org/wiki/Linear_interpolation) between the baseline and the original image. \n",
    "- You can think of interpolated images as small steps in the feature space between the baseline and the input, represented by $\\alpha$ in the original equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I42mBKXyjcIc"
   },
   "outputs": [],
   "source": [
    "alphas = tf.linspace(start=0.0, stop=1.0, num=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SWLSFOHsbgh"
   },
   "outputs": [],
   "source": [
    "def interpolate_images(baseline,\n",
    "                       image,\n",
    "                       alphas):\n",
    "    # Make alphas 4 dimensional to match the dimensions of our images and the baseline\n",
    "    alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "    # Batch dim for the baseline and the image\n",
    "    baseline_x = tf.expand_dims(baseline, axis=0)\n",
    "    input_x = tf.expand_dims(image, axis=0)\n",
    "    # Pixel change between the image and baseline\n",
    "    delta = input_x - baseline_x\n",
    "    # Get interpolated images\n",
    "    images = baseline_x +  alphas_x * delta\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4zFzbUBj684"
   },
   "source": [
    "Let's use the above function to generate interpolated images along a linear path at alpha intervals between a black baseline image and the example \"Fireboat\" image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgVx8swDQtTl"
   },
   "outputs": [],
   "source": [
    "interpolated_images = interpolate_images(\n",
    "    baseline=baseline,\n",
    "    image=img_name_tensors['Fireboat'],\n",
    "    alphas=alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QABFsuCvkO1h"
   },
   "source": [
    "Let's visualize the interpolated images. \n",
    "- Another way of thinking about the $\\alpha$ constant is that it is consistently increasing each interpolated image's intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "i = 0\n",
    "for alpha, image in zip(alphas[0::10], interpolated_images[0::10]):\n",
    "    i += 1\n",
    "    plt.subplot(1, len(alphas[0::10]), i)\n",
    "    plt.title(f'alpha: {alpha:.1f}')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7T0f1cqsaxA"
   },
   "source": [
    "### Compute gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tps0eWc0REqL"
   },
   "source": [
    "- Let's see how to calculate gradients in order to measure the relationship between changes to a feature and changes in the model's predictions. \n",
    "- For images, the gradient tells us which pixels have the strongest effect on the models predicted class probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouuVIsdfgukW"
   },
   "source": [
    "$IntegratedGrads^{approx}_{i}(x)::=(x_{i}-x'_{i})\\times\\sum_{k=1}^{m}\\frac{\\overbrace{\\partial F(\\text{interpolated images})}^\\text{compute gradients}}{\\partial x_{i}} \\times \\frac{1}{m}$\n",
    "\n",
    "where:  \n",
    "$F()$ = your model's prediction function  \n",
    "$\\frac{\\partial{F}}{\\partial{x_i}}$ = gradient (vector of partial derivatives $\\partial$) of your model F's prediction function relative to each feature $x_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hY_Ok3CoJW1W"
   },
   "source": [
    "We will use `tf.GradientTape` to compute gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JW1O9qEsxZOP"
   },
   "outputs": [],
   "source": [
    "def compute_gradients(model, images, target_class_idx):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # We use tape.watch here to tell Tensorflow GradientTape to trace all operations with the tensor 'images'\n",
    "        # When we train a model this step is not needed, since all trainable variables are \"watched\" automatically\n",
    "        tape.watch(images)\n",
    "        logits = model(images)\n",
    "        probs = tf.nn.softmax(logits, axis=-1)[:, target_class_idx]\n",
    "    return tape.gradient(probs, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's compute gradients for each image along the interpolation path with respect to the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHIR58rNJ3q_"
   },
   "outputs": [],
   "source": [
    "path_gradients = compute_gradients(\n",
    "    model=inception_v1,\n",
    "    images=interpolated_images,\n",
    "    target_class_idx=tf.constant(555)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path_gradients.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output dims**\n",
    "\n",
    "- 51 interpolated images\n",
    "- Height of the images\n",
    "- Width of the images\n",
    "- RGB channels\n",
    "\n",
    "We have a gradient for every pixel of all 51 interpolated images. The gradients essentially measure the change in your model's predictions for each small step in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmaPpr5bUtbr"
   },
   "source": [
    "#### Visualizing gradient saturation\n",
    "\n",
    "- These gradients describe *local* changes to the model's predicted probability of \"Fireboat\" and can *saturate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = inception_v1(interpolated_images)\n",
    "pred_proba = tf.nn.softmax(pred, axis=-1)[:, 555]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.plot(alphas, pred_proba)\n",
    "ax1.set_title('Target class predicted probability over alpha')\n",
    "ax1.set_ylabel('model p(target class)')\n",
    "ax1.set_xlabel('alpha')\n",
    "ax1.set_ylim([0, 1])\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "# Average across interpolation steps\n",
    "average_grads = tf.reduce_mean(path_gradients, axis=[1, 2, 3])\n",
    "# Normalize gradients to 0 to 1 scale. E.g. (x - min(x))/(max(x)-min(x))\n",
    "average_grads_norm = (average_grads-tf.math.reduce_min(average_grads))/(tf.math.reduce_max(average_grads)-tf.reduce_min(average_grads))\n",
    "ax2.plot(alphas, average_grads_norm)\n",
    "ax2.set_title('Average pixel gradients (normalized) over alpha')\n",
    "ax2.set_ylabel('Average pixel gradients')\n",
    "ax2.set_xlabel('alpha')\n",
    "ax2.set_ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ntMpA87jNN6"
   },
   "source": [
    "- The model \"learns\" the most from gradients at lower values of alpha. \n",
    "- For example, the gradients of the pixels of water cannons are sent to zero to make the correct prediction.\n",
    "- However it's still quite uncertain and focused on the bridge or water jet pixels as the alpha values approach the original input image.\n",
    "\n",
    "How to make sure that the correct pixels, e.g. of water cannons, are reflected as important for the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQdACCM6sJdW"
   },
   "source": [
    "### Accumulate gradients (integral approximation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHopk9evmO5P"
   },
   "source": [
    "- We will use Riemann sum to approximate IGs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GshPZQgROs80"
   },
   "source": [
    "$IntegratedGrads^{approx}_{i}(x)::=(x_{i}-x'_{i}) \\overbrace{\\sum_{k=1}^{m}}^\\text{Sum m local gradients}\n",
    "\\text{gradients(interpolated images)} \\overbrace{\\frac{1}{m}}^\\text{Divide by m steps}$\n",
    "\n",
    "- We can implement the above formula as an *average of the local gradients of `m` interpolated predictions and input images*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cMVl-Grx3lp"
   },
   "outputs": [],
   "source": [
    "def integral_approximation(gradients):\n",
    "    # riemann_trapezoidal\n",
    "    grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
    "    return integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JeF01fydNq0I"
   },
   "outputs": [],
   "source": [
    "ig = integral_approximation(gradients=path_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1ODXUevyGxL"
   },
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NcaTR-x8v1At"
   },
   "source": [
    "- Let's write a function to compute integrated gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5YdWHscoovhk"
   },
   "source": [
    "$IntegratedGrads^{approx}_{i}(x)::=\\overbrace{(x_{i}-x'_{i})}^\\text{5.}\\times \\overbrace{\\sum_{k=1}^{m}}^\\text{4.} \\frac{\\partial \\overbrace{F(\\overbrace{x' + \\overbrace{\\frac{k}{m}}^\\text{1.}\\times(x - x'))}^\\text{2.}}^\\text{3.}}{\\partial x_{i}} \\times \\overbrace{\\frac{1}{m}}^\\text{4.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjdfjp_3pHiY"
   },
   "source": [
    "1. Generate alphas $\\alpha$\n",
    "\n",
    "2. Generate interpolated images = $(x' + \\frac{k}{m}\\times(x - x'))$\n",
    "\n",
    "3. Compute gradients between model $F$ output predictions with respect to input features = $\\frac{\\partial F(\\text{interpolated path inputs})}{\\partial x_{i}}$\n",
    "\n",
    "4. Average integral approximation = $\\sum_{k=1}^m \\text{gradients} \\times \\frac{1}{m}$\n",
    "\n",
    "5. The term for the difference between the image and the baseline that scales integrated gradients with respect to imput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_H3k9Eu7Rl5"
   },
   "outputs": [],
   "source": [
    "def integrated_gradients(model, baseline, image, target_class_idx, m_steps=150, batch_size=32):\n",
    "    \n",
    "    # 1. Generate alphas\n",
    "    alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps)\n",
    "\n",
    "    # Accumulate gradients across batches\n",
    "    integrated_gradients = 0.0\n",
    "\n",
    "    # Batch alpha images\n",
    "    ds = tf.data.Dataset.from_tensor_slices(alphas).batch(batch_size)\n",
    "\n",
    "    for batch in ds:\n",
    "\n",
    "        # 2. Generate interpolated images\n",
    "        batch_interpolated_inputs = interpolate_images(\n",
    "            baseline=baseline,\n",
    "            image=image,\n",
    "            alphas=batch\n",
    "        )\n",
    "\n",
    "        # 3. Compute gradients between model outputs and interpolated inputs\n",
    "        batch_gradients = compute_gradients(\n",
    "            model=model,\n",
    "            images=batch_interpolated_inputs,\n",
    "            target_class_idx=target_class_idx\n",
    "        )\n",
    "\n",
    "        # 4. Average integral approximation. Summing integrated gradients across batches.\n",
    "        integrated_gradients += integral_approximation(gradients=batch_gradients)\n",
    "\n",
    "    # 5. Scale integrated gradients with respect to input\n",
    "    scaled_integrated_gradients = (image - baseline) * integrated_gradients\n",
    "        \n",
    "    return scaled_integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8G0ELl_wRrd0"
   },
   "outputs": [],
   "source": [
    "ig_attributions = integrated_gradients(\n",
    "    model=inception_v1,\n",
    "    baseline=baseline,\n",
    "    image=img_name_tensors['Fireboat'],\n",
    "    target_class_idx=555\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-LSHD2sajFf"
   },
   "source": [
    "- Check that the IG feature attributions have the same shape as the input \"Fireboat\" image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o55W6NYXGSZ8"
   },
   "source": [
    "### Visualize attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSQ6Y-DZvrQu"
   },
   "source": [
    "- Visualize attributions\n",
    "- Overlay them on the original image. \n",
    "- The code below sums the absolute values of the integrated gradients across the color channels to produce an attribution mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QN2cEA_WFym"
   },
   "outputs": [],
   "source": [
    "def plot_img_attributions(model, baseline, image, target_class_idx, m_steps=tf.constant(50), cmap=None, overlay_alpha=0.4):\n",
    "\n",
    "    attributions = integrated_gradients(\n",
    "        model=model,\n",
    "        baseline=baseline,\n",
    "        image=image,\n",
    "        target_class_idx=target_class_idx,\n",
    "        m_steps=m_steps\n",
    "    )\n",
    "\n",
    "    # Sum of the attributions across color channels for visualization.\n",
    "    # The attribution mask is a grayscale image with height and width\n",
    "    # equal to the original image.\n",
    "    attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n",
    "\n",
    "    axs[0, 0].set_title('Baseline image')\n",
    "    axs[0, 0].imshow(baseline)\n",
    "    axs[0, 0].axis('off')\n",
    "\n",
    "    axs[0, 1].set_title('Original image')\n",
    "    axs[0, 1].imshow(image)\n",
    "    axs[0, 1].axis('off')\n",
    "\n",
    "    axs[1, 0].set_title('Attribution mask')\n",
    "    axs[1, 0].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[1, 0].axis('off')\n",
    "\n",
    "    axs[1, 1].set_title('Overlay')\n",
    "    axs[1, 1].imshow(attribution_mask, cmap=cmap)\n",
    "    axs[1, 1].imshow(image, alpha=overlay_alpha)\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n73VxzbxeMvD"
   },
   "source": [
    "Looking at the attributions on the \"Fireboat\" image, we can see the model identifies the water cannons and spouts as contributing to its correct prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_img_attributions(\n",
    "    model=inception_v1,\n",
    "    image=img_name_tensors['Fireboat'],\n",
    "    baseline=baseline,\n",
    "    target_class_idx=555,\n",
    "    m_steps=500,\n",
    "    cmap=plt.cm.inferno,\n",
    "    overlay_alpha=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lo4SncDZfTw0"
   },
   "source": [
    "On the \"Giant Panda\" image, the attributions highlight the texture, nose, and the fur of the Panda's face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 2 new images for the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url_ex = {\n",
    "    'Black Beetle': 'https://storage.googleapis.com/applied-dl/temp/Lucanus.jpeg',\n",
    "    'Goldfinch': 'https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRF0_JmbeAmqCG9XUObIrN9CTgwRzUZycFKOQ&usqp=CAU'\n",
    "}\n",
    "\n",
    "img_paths_ex = {name: tf.keras.utils.get_file(name, url) for (name, url) in img_url_ex.items()}\n",
    "img_name_tensors_ex = {name: read_image(img_path) for (name, img_path) in img_paths_ex.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importance of baselines**\n",
    "\n",
    "- Use the image of the black beetle from `img_name_tensors_ex` and plot IG with the black baseline. The ImageNet label index is 307. Use m_steps=3500.\n",
    "- What can you see?\n",
    "- Create a white image (all ones) to use as a baseline.   \n",
    "- Plot IG of the beetle image for the new baseline. Use overlay_alpha=0.3 to better see the IG.\n",
    "- When a non-black baseline can be useful?\n",
    "- What can we say about the colour of a baseline in connection with the pixels of the image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baselines sampled from distributions**\n",
    "\n",
    "- Plot IG for the image of a goldfinch from `img_name_tensors_ex`, use the black baseline, m_steps=500 and the ImageNet label's index 12.\n",
    "- Generate a random uniform distribution in the range $[0,1]$.\n",
    "- Use it as a baseline for the goldfinch image (m_steps=500). Compare to the black baseline.\n",
    "- Generate 5 different uniform distributions, compute 5 different IG (m_steps=500), using those distributions as baselines.\n",
    "- Use the code from `plot_img_attributions` and plot the average attributions for all 5 baselines. You can choose any of those 5 generated baselines to plot as the baseline image.\n",
    "- What can you conclude looking at the attributions averaged over several baselines drawn from a uniform distribution?\n",
    "\n",
    "Hint: use `tf.random.uniform`, `tf.reduce_mean`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of IG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **IG provides local, not global interpretability**: IG provides a theoretically sound understanding of feature importances on individual examples. However, it does not provide a relative global feature importance for understanding overall model performance across data sets. It is important to keep in mind interpretation of these results can be potentially misleading and sensitive to feature baseline selection and relationships between features.\n",
    "\n",
    "*   **IG explains network predictions in relation to individual features, not feature interactions and combinations**: IG is doing a first-order linear approximation of the functional relationship between model outputs and individual input features so you still do not know how the individual features interact, which are correlated, and how the network combines features to make its prediction.\n",
    "\n",
    "*   **IG can only be applied to differentiable ML models**: This method cannot be applied to other types of ML models without modification such as tree-based models or model ensembles that involve non-differentiable parts.\n",
    "\n",
    "*   **Limitations of baseline selection and visual inspection**:Visual inspection of the IG prediction attributions does not by itself always highlight all pixels of importance and may require trying out a few different baselines and contrastive explanations to fully understand the model's learned representation. The method is blind to the colour you use as a baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find important features, which may indicate what data to add for retraining to improve the model. \n",
    "- Debugging data skew. For instance, tracking IG feature importances across time (e.g. \"next day\" splits) and data splits (e.g. train/val/test splits) allows for meaningful monitoring of train-serving feature drift and skew. Think of a model that needs to predict new data daily, but the data changes over time.\n",
    "- Find unimportant features that the model considers important, which might lead to possible errors. \n",
    "- Check how robust your model to feature distortions through identifying feature importance of the new picture."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "integrated_gradients.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
