{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "div.cell { /* Tunes the space between cells */\n",
       "margin-top:1em;\n",
       "margin-bottom:1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
       "font-size: 2.2em;\n",
       "line-height:1.4em;\n",
       "text-align:center;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
       "margin-bottom: -0.4em;\n",
       "}\n",
       "\n",
       "\n",
       "div.text_cell_render { /* Customize text cells */\n",
       "font-family: 'Arial';\n",
       "font-size:1.5em;\n",
       "line-height:1.4em;\n",
       "padding-left:3em;\n",
       "padding-right:3em;\n",
       "}\n",
       "\n",
       ".MathJax {\n",
       "    font-size: 70%;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "css_file = './custom.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "© 2018 Daniel Voigt Godoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intuitiveml.supervised.classification.DecisionTree import *\n",
    "from intuitiveml.utils import gen_button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definition\n",
    "\n",
    "From the Scikit-Learn [website](https://scikit-learn.org/stable/modules/tree.html):\n",
    "    \n",
    "    Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "A bit more informally: A decision tree is a model that ***splits*** the ***feature space*** in such a way that ***samples similar to each other*** end up together. In other words, it tries to ***minimize the heterogeneity*** of samples that fall under a same set of rules (splits).\n",
    "\n",
    "We saw already that both ***entropy*** and ***gini impurity*** are ***zero*** whenever ***all samples belong to the same class***. So, we can use either one of those to make the best split of our data!\n",
    "\n",
    "### How to choose the splitting threshold?\n",
    "\n",
    "We can try splitting it in two at different thresholds, computing the ***entropy*** (or ***gini impurity***) for both subsets and averaging the results, weighted by the number of samples in each subset.\n",
    "\n",
    "Then we pick the threshold that yielded the least entropy.\n",
    "\n",
    "$$\n",
    "Entropy_{after} = \\frac{N_{left}}{N}Entropy_{left} + \\frac{N_{right}}{N}Entropy_{right}\n",
    "$$\n",
    "\n",
    "Easy, right?\n",
    "\n",
    "This is the basic idea behind the ***Classification And Regression Tree (CART)*** algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment\n",
    "\n",
    "Time to try it yourself!\n",
    "\n",
    "You have 10 data points of two colors: red and green! These are your ***labels***.\n",
    "\n",
    "Each point is has a single numerical coordinate. This is your ***feature***.\n",
    "\n",
    "You want to start training your decision tree, so you need to choose ***where*** to make the first split.\n",
    "\n",
    "The slider control below allows you to change the splitting threshold (the star). Changing the threshold modifies the resulting distributions of both ***left*** and ***right*** subsets and the corresponding ***entropies***. The ***entropy after*** the split is shown at the title.\n",
    "\n",
    "Use the slider to play with different configurations and answer the ***questions*** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 First Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data()\n",
    "mydt = plotDecision(x=x, y=y, idx_mid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fund/lib/python3.6/site-packages/plotly/tools.py:465: DeprecationWarning:\n",
      "\n",
      "plotly.tools.make_subplots is deprecated, please use plotly.subplots.make_subplots instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ae9c8c778146ee81d5975834e16c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'marker': {'color': 'black'},\n",
       "              'mode': 'lines',\n",
       "     …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vb0 = VBox(build_figure(mydt), layout={'align_items': 'center'})\n",
    "vb0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "1. The splitting thresholds are located at the midpoints. What would happen if they were located differently?\n",
    "2. What is the threshold that minimizes entropy?\n",
    "3. What if we multiply all values by a factor of 10? 100? What does it change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Split Result\n",
    "\n",
    "If you minimized the entropy correctly, this is what your split should looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc5f7e5305d4755a3eb99509d82f89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Tree 1', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_button('Tree 1', mydt.plot_tree(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, you grew your first tree!\n",
    "\n",
    "### Understanding a Decision Tree\n",
    "\n",
    "There are a few important characteristics of your tree to take notice:\n",
    "\n",
    "1. Performing ***one*** split means your Decision Tree has a ***depth*** of ***one***.\n",
    "2. Each resulting node at this point is a ***leaf***, as they don't have any other nodes under them. \n",
    "3. Each ***leaf node*** will have a given number of samples (N_left and N_right). These are the ***samples per leaf***.\n",
    "4. The difference between ***entropy before and after*** is your ***information gain***.\n",
    "\n",
    "#### Depth, Samples per Leaf and Information Gain are some of the criteria used to decide when to STOP growing a tree!\n",
    "\n",
    "### Understanding its Nodes\n",
    "\n",
    "Each node has two additional pieces of information (besides number of samples and entropy):\n",
    "- value\n",
    "- class\n",
    "\n",
    "***Value*** is a list containing the number of samples belonging to each class. For instance, take the node on left side of the first split. Its value reads [3, 1], meaning it has 3 red samples and 1 green sample. \n",
    "\n",
    "***IMPORTANT***: This information allows you to compute the ***probability*** of a sample being ***green*** (for that node), which is 1 / 4 in the example.\n",
    "\n",
    "***Class*** is the class to which the majority of samples in that node belong. For the same node, its class is ***red***, as it has 3 red samples and only 1 green sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Second Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're happy with your choice of threshold on the first split, you can work your way through the ***second split***.\n",
    "\n",
    "If any of the resulting subsets in the first split has ***zero entropy***, your tree already ***succeeded in isolating a group of homogeneous samples***, so ***no more splitting*** on that branch is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "left1 = right1 = None\n",
    "def prefunc1():\n",
    "    global left1, right1\n",
    "    left1, right1 = mydt.left_split, mydt.right_split\n",
    "    fl1 = build_figure(left1, width=450)\n",
    "    fr1 = build_figure(right1, width=450)\n",
    "\n",
    "    vb1 = HBox((VBox(fl1, layout={'align_items': 'center'}),\n",
    "                VBox(fr1, layout={'align_items': 'center'})))\n",
    "    return vb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b401f968ac2d4956b14e6bee80ebf9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Second Split', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_button('Second Split', prefunc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "1. What is the threshold that minimizes entropy?\n",
    "2. Go back to the ***First Split*** and split it at ***-0.30*** threshold. Then click ***Hide*** and ***Show*** the second split to refresh it. Which threshold(s) minimize entropy? Is this better or worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Split Result\n",
    "\n",
    "If you minimized the entropy at every depth correctly, this is what your splits should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc5473842e046f38d2f836e35a571d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Tree 2', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_button('Tree 2', mydt.plot_tree(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Third Split\n",
    "\n",
    "Before proceeding, go back to the ***first split*** and choose the threshold that minimizes its entropy. Then ***refresh*** (by clicking Hide/Show) the ***second split*** and choose its threshold as well.\n",
    "\n",
    "Once you're done with it, you can work your way through the ***third split***.\n",
    "\n",
    "NOTE: the ***third split*** operates on the ***leftmost branch of the tree*** only! If you chose the correct thresholds, its right branch from the top should have green samples only (check ***Tree 2***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "left2 = right2 = None\n",
    "def prefunc2():\n",
    "    global left2, right2\n",
    "    left2, right2 = left1.left_split, left1.right_split\n",
    "    fl1l2 = build_figure(left2, width=450)\n",
    "    fl1r2 = build_figure(right2, width=450)\n",
    "\n",
    "    vb2 = HBox((VBox(fl1l2, layout={'align_items': 'center'}),\n",
    "                VBox(fl1r2, layout={'align_items': 'center'})))\n",
    "\n",
    "    return vb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0be970d081c4a9e8c6f78b98e9a81bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Third Split', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_button('Third Split', prefunc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "1. What is the threshold that minimizes entropy?\n",
    "2. Can you grow your tree further? If yes, what's the next step? If no, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Split Result\n",
    "\n",
    "If you minimized the entropy at every depth correctly, this is what your splits should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c007ed3cd754b68b1b8e1a6aaa3520e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Tree 3', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_button('Tree 3', mydt.plot_tree(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Questions:\n",
    "\n",
    "3. What is the depth of ***Tree 3***?\n",
    "4. How many ***leaf nodes*** does it have?\n",
    "5. What do all those ***leaf*** nodes have in common?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have built your Decision Tree, you can take any numerical coordinate (your ***feature***), ***follow the splits*** and arrive at a corresponding ***leaf node***.\n",
    "\n",
    "At the leaf node, you can check its ***class*** to get the predicted class straight away. Moreover, you can use its ***values*** to compute the probability associated with the predicted class (if you don't remember how to do it, revisit the ***Understanding its Nodes*** section above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "1. What are the ***probabilities*** associated with the predicted class for each one of the ***4 leaf nodes*** on ***Tree 3***?\n",
    "2. What about the ***3 leaf nodes*** on ***Tree 2***?\n",
    "\n",
    "Once you answered those questions, click on the button below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/fund/lib/python3.6/site-packages/plotly/tools.py:465: DeprecationWarning:\n",
      "\n",
      "plotly.tools.make_subplots is deprecated, please use plotly.subplots.make_subplots instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1660cc82af7c4772803823d2cf11318a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Probabilities', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_button('Probabilities', VBox(build_figure_prob(mydt), layout={'align_items': 'center'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Questions:\n",
    "\n",
    "3. What happens if you choose a ***shallow*** tree (low depth)? What's the impact on predictions?\n",
    "4. What about a ***deep*** tree (high depth)?\n",
    "5. What about an average depth?\n",
    "6. Which one do you think will yield better predictions for unseen data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scikit-Learn\n",
    "\n",
    "[Decision Trees](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "Please check Aurelién Geron's \"Hand-On Machine Learning with Scikit-Learn and Tensorflow\" notebook on Decision Trees [here](http://nbviewer.jupyter.org/github/ageron/handson-ml/blob/master/06_decision_trees.ipynb)\n",
    "\n",
    "See Scikit-Learn website for [tips on practical use](https://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. More Resources\n",
    "\n",
    "[InfoGraphic](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/Info-graphs/Day%2023.jpg)\n",
    "\n",
    "[A visual introduction to machine learning](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n",
    "\n",
    "[Interactive Visualization of Decision Trees with Jupyter Widgets](https://towardsdatascience.com/interactive-visualization-of-decision-trees-with-jupyter-widgets-ca15dd312084)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This material is copyright Daniel Voigt Godoy and made available under the Creative Commons Attribution (CC-BY) license ([link](https://creativecommons.org/licenses/by/4.0/)). \n",
    "\n",
    "#### Code is also made available under the MIT License ([link](https://opensource.org/licenses/MIT))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
